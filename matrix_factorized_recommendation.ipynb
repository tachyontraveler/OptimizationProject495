{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import sys\n",
    "import autograd.numpy.random as npr\n",
    "from autograd.misc.optimizers import adam\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Defaults and Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = './datafiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OWrite(s):\n",
    "    print(s)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def saveh5py(hdata,hname):\n",
    "    h5f = h5py.File(datadir+hname, 'w')\n",
    "    h5f.create_dataset('dataset', data=hdata)\n",
    "    h5f.close()\n",
    "\n",
    "def readh5py(hname):\n",
    "    h5f = h5py.File(datadir+hname,'r')\n",
    "    hdata = h5f['dataset'][:]\n",
    "    h5f.close()\n",
    "    return hdata\n",
    "\n",
    "def gen_dmatrix(data,matrix_shape):\n",
    "    initTime = datetime.now()\n",
    "    dmatrix = np.zeros(matrix_shape)\n",
    "    for item in data:\n",
    "        dmatrix[item[0],item[1]] = item[2]\n",
    "    saveh5py(dmatrix,'dmatrix.h5')\n",
    "    OWrite (\"Time spent on computing data matrix: \"+str(datetime.now() - initTime))\n",
    "    return dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self,args):\n",
    "        self.alpha       = args['alpha']\n",
    "        self.L           = args['L']\n",
    "        self.max_epochs  = args['max_epochs']\n",
    "        self.xtrain      = args['xtrain']\n",
    "        self.num_users   = len(args['unique_cust_ids_list'])\n",
    "        self.num_movies  = len(args['unique_movie_ids_list'])\n",
    "        self.dmatrix     = gen_dmatrix(self.xtrain,(self.num_users,self.num_movies))\n",
    "        self.UL = np.random.normal(scale=1./self.L, size=(self.num_users, self.L))\n",
    "        self.ML = np.random.normal(scale=1./self.L, size=(self.num_movies, self.L))\n",
    "        self.BU = np.zeros(self.num_users)\n",
    "        self.BM = np.zeros(self.num_movies)\n",
    "        self.b  = np.mean(xtrain[:,-1])\n",
    "\n",
    "    def model(self,params):\n",
    "        ul,ml,bu,bm = params\n",
    "        return self.b + bu[:,np.newaxis] + bm[np.newaxis:,] + ul.dot(ml.T)\n",
    "\n",
    "    def squared_error(self,params,y):\n",
    "        return (np.square(y-model(params)))\n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        for xtem in self.xtrain:\n",
    "            params = (self.UL[xtem[0]],self.ML[xtem[1]],self.BU[xtem[0]],self.BM[xtem[1]])\n",
    "            params = params - (self.alpha*self.gradient_fn(params,xtem[2]))\n",
    "        \n",
    "    def train(self):\n",
    "        self.gradient_fn = grad(self.squared_error,0)\n",
    "        for i_e in range(self.max_epochs):\n",
    "            np.random.shuffle(self.xtrain)\n",
    "            gradient_descent()\n",
    "            avg_error = overall_mse()\n",
    "            lossdata.append(avg_error)\n",
    "            OWrite(\"Epoch: {} \\t MSE: {:.4f}\".format(i_e+1,avg_error))\n",
    "        return lossdata\n",
    "            \n",
    "            \n",
    "    def predict_matrix(self):\n",
    "        return self.b + self.BU[:,np.newaxis] + self.BM[np.newaxis:,] + self.UL.dot(self.ML.T)\n",
    "    \n",
    "    def overall_mse(self):\n",
    "        xs, ys = self.dmatrix.nonzero()\n",
    "        pred_matrix = self.predict_matrix()\n",
    "        return np.sqrt(sum([pow(self.dmatrix[x,y]-pred_matrix[x,y],2) for x,y in zip(xs,ys)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data                 = readh5py('converted_final_data.h5')\n",
    "global_var_cust_ids  = np.genfromtxt(datadir+'final_custids.csv',dtype=int)\n",
    "global_var_movie_ids = np.genfromtxt(datadir+'final_movieids.csv',dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWrite (\"Splitting data to train and test sets\")\n",
    "xtrain, xtest = train_test_split(data, test_size=0.1, random_state=7)\n",
    "saveh5py(xtrain,'traindata.h5')\n",
    "saveh5py(xtest,'testdata.h5')\n",
    "OWrite (\"Shape of training data: \"+str(xtrain.shape))\n",
    "OWrite (\"Shape of test data: \"+str(xtest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'alpha'     : 0.001,\n",
    "        'L'         : 20,\n",
    "        'xtrain'    : xtrain,\n",
    "        'max_epochs': 100,\n",
    "        'unique_cust_ids_list' : np.copy(global_var_cust_ids),\n",
    "        'unique_movie_ids_list': np.copy(global_var_movie_ids) ,\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rs = npr.RandomState(0)\n",
    "a = rs.randn(6,2)\n",
    "b = rs.randn(5,1)\n",
    "print (a,b)\n",
    "def tmp_fn(params,ic):\n",
    "    ia,ib = params\n",
    "    return pow(pow(ia[0],2)+pow(ia[1],2)+pow(ib[0],3)+5. - ic,2)\n",
    "tmp_grad = grad(tmp_fn,0)\n",
    "c=(a[1],b[2])\n",
    "print(tmp_grad(c,4))\n",
    "c=(a[1],b[3])\n",
    "print(tmp_grad(c,4))\n",
    "print (c+tmp_grad(c,4)) \n",
    "'''\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (495_ann_py3.7)",
   "language": "python",
   "name": "eecs495_ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
