{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A script to sample data from the huge Netflix prize dataset so as to validate the ML algorithms within limited computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import sys\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_samples = 3000000 ## Maximum number of samples in the dataset\n",
    "n_custs   = 50000       ## Number of customers (users) to be included in the datset\n",
    "datadir = './datafiles/'   ## Directory to save and retrieve data\n",
    "load_saved = False      ## To get the initial full raw data from file current_full_data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OWrite(s):\n",
    "    print(s)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def saveh5py(hdata,hname):\n",
    "    h5f = h5py.File(datadir+hname, 'w')\n",
    "    h5f.create_dataset('dataset', data=hdata)\n",
    "    h5f.close()\n",
    "\n",
    "def readh5py(hname):\n",
    "    h5f = h5py.File(datadir+hname,'r')\n",
    "    hdata = h5f['dataset'][:]\n",
    "    h5f.close()\n",
    "    return hdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To read raw data\n",
    "def read_data():\n",
    "    initTime = datetime.now()\n",
    "    if load_saved:\n",
    "        data = readh5py('current_full_data.h5')\n",
    "        OWrite (\"Time spent in data load: \"+str(datetime.now() - initTime))\n",
    "        return data\n",
    "    data = []\n",
    "    for filename in ['1']: #['1','2','3','4']:\n",
    "        filename = datadir+'dataset/combined_data_'+filename+'.txt'\n",
    "        for line in open(filename,'r').read().strip().split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.endswith(':'):\n",
    "                movie_title = (line[:-1])\n",
    "            else:\n",
    "                data.append([movie_title]+line.split(','))            \n",
    "    data = (np.array(data)[:,:-1]).astype(int)\n",
    "    data[:,[0,1]] = data[:,[1,0]]\n",
    "    saveh5py(data,'current_full_data.h5')\n",
    "    OWrite (\"Time spent in data load: \"+str(datetime.now() - initTime))\n",
    "    return data\n",
    "\n",
    "\n",
    "# Random sampling\n",
    "def sample_data(data):\n",
    "    return data[np.random.choice(data.shape[0], n_max_samples, replace=False),:]\n",
    "\n",
    "\n",
    "# To get indices of randomly selected movies and customers and if needed, restrict their numbers\n",
    "def get_indices(data):\n",
    "    cust_ids,n_counts = np.unique(data[:,0],return_counts=True)\n",
    "    cust_ids = cust_ids[np.argpartition(n_counts, -1*n_custs)[-1*n_custs:]]\n",
    "                #cust_ids[np.random.choice(len(cust_ids), n_custs, replace=False)]\n",
    "    cust_ids.sort()\n",
    "    cust_ids = list(cust_ids)\n",
    "    OWrite('final number of customers: '+str(len(cust_ids)))\n",
    "    \n",
    "    movie_ids = np.unique(data[:,1])\n",
    "    movie_ids.sort()\n",
    "    movie_ids = list(movie_ids)\n",
    "    OWrite('final number of movies: '+str(len(movie_ids)))\n",
    "    return cust_ids,movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load and process\n",
    "\n",
    "OWrite (\"Calling function to load the full raw data\")\n",
    "xtrain = read_data()\n",
    "OWrite (\"Loaded full data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To limit the dataset size so that the algorithms can be run in the local systems\n",
    "xtrain = sample_data(xtrain)\n",
    "OWrite (\"Sampled the data to include {} datapoints\".format(n_max_samples))\n",
    "global_var_cust_ids, global_var_movie_ids = get_indices(xtrain)\n",
    "OWrite (\"Listed the IDs of coustomers and movies as global variables\")\n",
    "np.savetxt(datadir+'final_custids.csv',global_var_cust_ids,fmt=\"%i\")\n",
    "np.savetxt(datadir+'final_movieids.csv',global_var_movie_ids,fmt=\"%i\")\n",
    "OWrite (\"Saved the global variables to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Movie and User Indices to continuous\n",
    "\n",
    "def convert_indices(item):\n",
    "    if item[0] in global_var_cust_ids:\n",
    "        item[0] = global_var_cust_ids.index(item[0])\n",
    "        item[1] = global_var_movie_ids.index(item[1])\n",
    "    else:\n",
    "        item = [0,0,0]\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A parallelized system to convert non-continuous Netflix user IDs to continuous for convenience\n",
    "OWrite (\"User IDs are discontinuous in this dataset. Converting indices to continuous.\")\n",
    "initTime = datetime.now()\n",
    "p = Pool()\n",
    "xtrain = p.map(convert_indices,xtrain)\n",
    "OWrite (\"Time spent on conversion: \"+str(datetime.now() - initTime))\n",
    "xtrain = np.array(xtrain)\n",
    "xtrain = xtrain[~np.all(xtrain == 0, axis=1)]\n",
    "OWrite (\"Shape of final full data after conversion: \"+str(xtrain.shape))\n",
    "saveh5py(xtrain,'converted_final_data.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (495_ann_py3.7)",
   "language": "python",
   "name": "eecs495_ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
